{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning CNN model to recognize faces"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifying training path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpath = 'Face Images/Final Training Images'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining pre-processing transformations on raw images of training data\n",
    "# These hyper parameters helps to generate slightly twisted versions\n",
    "# of the original image, which leads to a better model, since it learns\n",
    "# on the good and bad mix of images\n",
    "train_datagen = ImageDataGenerator(\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining pre-processing transformations on raw images of testing data\n",
    "# No transformations are done on the testing images\n",
    "test_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 244 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generate training data\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    trainpath,\n",
    "    target_size=(64,64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 244 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generate testing data\n",
    "testing_set = test_datagen.flow_from_directory(\n",
    "    trainpath,\n",
    "    target_size=(64,64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'face1': 0,\n",
       " 'face10': 1,\n",
       " 'face11': 2,\n",
       " 'face12': 3,\n",
       " 'face13': 4,\n",
       " 'face14': 5,\n",
       " 'face15': 6,\n",
       " 'face16': 7,\n",
       " 'face2': 8,\n",
       " 'face3': 9,\n",
       " 'face4': 10,\n",
       " 'face5': 11,\n",
       " 'face6': 12,\n",
       " 'face7': 13,\n",
       " 'face8': 14,\n",
       " 'face9': 15}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing class labels for each face\n",
    "testing_set.class_indices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating lookup table for all faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of Face and its ID: {0: 'face1', 1: 'face10', 2: 'face11', 3: 'face12', 4: 'face13', 5: 'face14', 6: 'face15', 7: 'face16', 8: 'face2', 9: 'face3', 10: 'face4', 11: 'face5', 12: 'face6', 13: 'face7', 14: 'face8', 15: 'face9'}\n",
      "\n",
      " The number of output neurons: 16\n"
     ]
    }
   ],
   "source": [
    "# class_indices have the numeric tag for each face\n",
    "train_classes = training_set.class_indices\n",
    "\n",
    "# storing the faces and the numeric tag for future reference\n",
    "resultMap = {}\n",
    "for faceValue, faceName in zip(train_classes.values(),train_classes.keys()):\n",
    "    resultMap[faceValue] = faceName\n",
    "\n",
    "# saving the face map for future reference\n",
    "import pickle\n",
    "with open('resultMap.pkl','wb') as file:\n",
    "    pickle.dump(resultMap, file)\n",
    "file.close()\n",
    "\n",
    "print(\"Mapping of Face and its ID:\",resultMap)\n",
    "\n",
    "# the number of neurons for the output layer is equal to number of faces\n",
    "output_neurons = len(resultMap)\n",
    "print('\\n The number of output neurons:',output_neurons)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 60, 60, 32)        2432      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 30, 30, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 26, 26, 64)        51264     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 13, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 10816)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                692288    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 747,024\n",
      "Trainable params: 747,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 19:07:23.793773: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPool2D, Flatten, Dense\n",
    "\n",
    "# initializing the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# step 1 : convolution\n",
    "classifier.add(Convolution2D(32, kernel_size=(5,5), strides=(1,1),input_shape = (64,64,3), activation='relu'))\n",
    "\n",
    "# step 2 : max pooling\n",
    "classifier.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "# additional layer for convolution and max pooling\n",
    "classifier.add(Convolution2D(64, kernel_size=(5,5), strides=(1,1), activation='relu'))\n",
    "\n",
    "classifier.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "# step 3 : flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# step 4 : fully connected neural network\n",
    "classifier.add(Dense(64, activation='relu'))\n",
    "\n",
    "classifier.add(Dense(output_neurons, activation='softmax'))\n",
    "\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yz/4zp0zzb50w71fn6jwfwny__c0000gn/T/ipykernel_35268/3671566285.py:9: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  classifier.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - ETA: 0s - loss: 2.8231 - accuracy: 0.1125WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 2.8231 - accuracy: 0.1125 - val_loss: 2.9560 - val_accuracy: 0.0656\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 3.0644 - accuracy: 0.1486\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 2.4417 - accuracy: 0.2375\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 2.6689 - accuracy: 0.2635\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 1.8779 - accuracy: 0.4054\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 1.4216 - accuracy: 0.5541\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.6934 - accuracy: 0.8108\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.5387 - accuracy: 0.8176\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.4152 - accuracy: 0.8875\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.1829 - accuracy: 0.9730\n",
      "Training time: 0 minutes\n"
     ]
    }
   ],
   "source": [
    "# compiling the CNN\n",
    "classifier.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "import time\n",
    "# measuring time taken to train the model\n",
    "start_time = time.time()\n",
    "\n",
    "# starting model training\n",
    "classifier.fit_generator(\n",
    "    training_set,\n",
    "    steps_per_epoch=5,\n",
    "    epochs = 10,\n",
    "    validation_data=testing_set,\n",
    "    validation_steps=10\n",
    ")\n",
    "end_time = time.time()\n",
    "print('Training time:',round((end_time-start_time)/60),'minutes')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the CNN classifier on unseen images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is: face4\n"
     ]
    }
   ],
   "source": [
    "# making single predictions\n",
    "import numpy as np\n",
    "import keras.utils as image\n",
    "\n",
    "imgpath = 'Face Images/Final Testing Images/face4/3face4.jpg'\n",
    "test_img = image.load_img(imgpath,target_size = (64,64))\n",
    "test_img = image.img_to_array(test_img)\n",
    "\n",
    "test_img = np.expand_dims(test_img,axis=0)\n",
    "result = classifier.predict(test_img,verbose=0)\n",
    "print(\"Prediction is:\",resultMap[np.argmax(result)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
